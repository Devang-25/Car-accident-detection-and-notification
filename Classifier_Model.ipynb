{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_ipython().magic(u'matplotlib inline')\n",
    "import numpy\n",
    "import timeit\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "import skimage\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split   ### import sklearn tool\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to load video from file\n",
    "\n",
    "def load_set(videofile):\n",
    "    all_frames = []\n",
    "    vidcap = cv2.VideoCapture(videofile)\n",
    "    success,image = vidcap.read()\n",
    "    count = 0       \n",
    "    error = ''      \n",
    "    success = True  \n",
    "\n",
    "    img = []        \n",
    "    while success: \n",
    "        success, img = vidcap.read()  \n",
    "        count += 1  \n",
    "        frames = []  \n",
    "        for j in range(0,99):\n",
    "            try:\n",
    "                success, img = vidcap.read()\n",
    "                tmp = skimage.color.rgb2gray(numpy.array(img))\n",
    "                tmp = skimage.transform.downscale_local_mean(tmp, (5,5))\n",
    "                frames.append(tmp)\n",
    "                count+=99\n",
    "            except:\n",
    "                count+=1\n",
    "    \n",
    "        if numpy.shape(frames)==(99, 144, 256):\n",
    "            all_frames.append(frames)\n",
    "        elif numpy.shape(frames[0])==(144,256):\n",
    "            all_frames.append(numpy.concatenate((all_frames[-1][-(99-len(frames)):], frames)))\n",
    "        elif numpy.shape(frames[0])!=(144,256):\n",
    "            error = 'Video is of incorrect resolution.'\n",
    "    vidcap.release()\n",
    "    del frames; del image\n",
    "    return all_frames, error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "img_filepath = '' \n",
    "neg_all = glob.glob(img_filepath + 'negative/*.mp4')               \n",
    "pos_all = glob.glob(img_filepath + 'positive/*.mp4')                 \n",
    "\n",
    "all_files = (pos_all + neg_all)\n",
    "print(len(neg_all), len(pos_all))\n",
    "print(len(all_files))\n",
    "\n",
    "def label_matrix(values):\n",
    "    n_values = numpy.max(values) + 1    \n",
    "    return numpy.eye(n_values)[values]\n",
    "\n",
    "labels = numpy.concatenate(([1]*len(pos_all), [0]*len(neg_all[0:len(pos_all)])))\n",
    "labels = label_matrix(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(rand):\n",
    "    seq1 = numpy.zeros((len(rand), 99, 144, 256))\n",
    "    for i,fi in enumerate(rand):                    \n",
    "        print (i, fi)                               \n",
    "        if fi[-4:] == '.mp4':\n",
    "            t = load_set(fi)                        \n",
    "        if np.ndim(t) == (99,144,256):              \n",
    "            seq1[i] = t\n",
    "        else:# TypeError\n",
    "            'Image has shape ', np.ndim(t), 'but needs to be shape', np.ndim(seq1[0])        \n",
    "    print (np.ndim(seq1))\n",
    "    return seq1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from array import array\n",
    "import numpy as np\n",
    "\n",
    "#only testing\n",
    "x_testA = np.asarray(all_files)\n",
    "y_testA = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 positive/positive.mp4\n",
      "1 positive/positive1.mp4\n",
      "2 positive/positive3.mp4\n",
      "3 positive/positive2.mp4\n",
      "4 negative/negative.mp4\n",
      "5 negative/negative2.mp4\n",
      "6 negative/negative1.mp4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "\n",
    "batch_size = 15\n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "row_hidden = 128\n",
    "col_hidden = 128\n",
    "frame, row, col = (99, 144, 256)\n",
    "\n",
    "x = Input(shape=(frame, row, col))\n",
    "encoded_rows = TimeDistributed(LSTM(row_hidden))(x)  \n",
    "encoded_columns = LSTM(col_hidden)(encoded_rows)\n",
    "\n",
    "### set up prediction and compile the model\n",
    "prediction = Dense(num_classes, activation='softmax')(encoded_columns)\n",
    "model = Model(x, prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
